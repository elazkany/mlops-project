name: Train, Evaluate and Report

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

permissions: write-all

jobs:
  train_and_report_eval_performance:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout 
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.10.12

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # Or wherever flake8 is listed

      - name: Lint with flake8 # The flake8 library was installed as a dependency in the requirements.txt file
        run: flake8 src tests --statistics

      - name: Run unit tests with pytest
        run: PYTHONPATH=src pytest -v --cov=src --cov-report=term-missing

      # Setup CML GitHub Action
      - name: Set up CML
        uses: iterative/setup-cml@v1

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Reproduce DVC pipeline
        run: |
          echo "ðŸ§ª Running DVC pipeline..."
          dvc repro

      - name: Commit and push DVC-tracked outputs
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Set generic Git identity using GitHub Actions-provided variables
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          dvc push

          git commit -m "Update metrics and plots from CI" || echo "Nothing to commit"
          git push || echo "Nothing to push"

      - name: Write CML report
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "# ðŸ§ª Model Evaluation Report" >> model_eval_report.md

          echo "## ðŸ” Model Comparison" >> model_eval_report.md
          
          {
            echo "### ðŸ“Š Metrics Comparison"
            echo "| Model | Accuracy | F1 Score | Precision | Recall |"
            echo "|--------|----------|----------|------------|--------|"
            jq -r 'to_entries[] | [.key, (.value.accuracy // "NA"), (.value.f1_score // "NA"), (.value.precision // "NA"), (.value.recall // "NA")] | @tsv' reports/compare_metrics.json |
              while IFS=$'\t' read -r model acc f1 prec rec; do
                echo "| $model | $acc | $f1 | $prec | $rec |"
              done
          } >> model_eval_report.md

          echo "### Confusion Matrices" >> model_eval_report.md

          echo "![Confusion Matrix Comparison](./reports/compare_confusion_matrices.png)" >> model_eval_report.md

          best_model_name=$(mlflow search-runs --experiment-name "credit-card-fraud-detection" \
            --filter-tag "best_model = 'true'" \
            --output json | jq -r '.[0].tags.run_name')


          echo "## ðŸ† Best Model" >> model_eval_report.md

          echo "### Metrics" >> model_eval_report.md

          {
            echo "| Accuracy | F1 Score | Precision | Recall |"
            echo "|----------|----------|------------|--------|"
            jq -r '[.accuracy, .f1_score, .precision, .recall] | @tsv' reports/best_model_metrics.json |
              while IFS=$'\t' read -r acc f1 prec rec; do
                echo "| $acc | $f1 | $prec | $rec |"
              done
          } >> model_eval_report.md

          echo "### Confusion Matrix" >> model_eval_report.md

          echo "![Best Model Confusion Matrix](./reports/best_model_confusion_matrix.png)" >> model_eval_report.md

          # Create comment from markdown report
          cml comment create model_eval_report.md

  deploy_and_test_container:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build Docker image
        run: docker build -t fraud-api .

      - name: Run Docker container
        run: |
          docker run -d -p 8000:8000 --name fraud-api fraud-api
          sleep 10  # wait for API to start

      - name: Test /predict endpoint
        run: |
          curl -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{
              "Time": -0.5073720321, "V1": -16.5265065691, "V2": 8.5849717959, "V3": -18.6498531852,
              "V4": 9.5055935151, "V5": -13.7938185271, "V6": -2.8324042994, "V7": -16.701694296,
              "V8": 7.5173439037, "V9": -8.5070586368, "V10": -14.1101844415, "V11": 5.2992363496,
              "V12": -10.8340064815, "V13": 1.6711202533, "V14": -9.3738585836, "V15": 0.3608056416,
              "V16": -9.8992465408, "V17": -19.2362923698, "V18": -8.3985519949, "V19": 3.1017353689,
              "V20": -1.5149234353, "V21": 1.1907386948, "V22": -1.127670009, "V23": -2.3585787698,
              "V24": 0.673461329, "V25": -1.4136996746, "V26": -0.4627623614, "V27": -2.0185752488,
              "V28": -1.0428041697, "Amount": 4.7815272829
            }'

      - name: Stop and remove Docker container
        if: always()
        run: docker rm -f fraud-api
      

